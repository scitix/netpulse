# æ€§èƒ½è°ƒä¼˜æŒ‡å—

NetPulse æ”¯æŒéƒ¨åˆ†æ€§èƒ½ä¼˜åŒ–å‚æ•°ï¼Œå¸®åŠ©ç”¨æˆ·æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´ç³»ç»Ÿæ€§èƒ½ã€‚

## ä¸»è¦ä¼˜åŒ–ç‚¹

- è¿æ¥æ± å‚æ•°ï¼ˆå¦‚æœ€å¤§è¿æ¥æ•°ã€è¶…æ—¶æ—¶é—´ï¼‰
- ç¼“å­˜ï¼ˆå¦‚Redisç¼“å­˜ï¼Œttlè®¾ç½®ï¼‰
- æ•°æ®åº“è¿æ¥æ± å‚æ•°

## è¿æ¥æ± é…ç½®

```yaml
connection_pool:
  max_size: 50           # æœ€å¤§è¿æ¥æ•°
  min_size: 10           # æœ€å°è¿æ¥æ•°
  max_idle_time: 300     # ç©ºé—²è¶…æ—¶æ—¶é—´
  keepalive_interval: 60 # ä¿æ´»é—´éš”
```

## ç¼“å­˜é…ç½®

```yaml
cache:
  ttl: 3600              # ç¼“å­˜æœ‰æ•ˆæœŸ
  max_size: 1000         # æœ€å¤§ç¼“å­˜æ¡ç›®
  eviction_policy: "lru" # æ·˜æ±°ç­–ç•¥
```

## æ•°æ®åº“ä¼˜åŒ–

```yaml
database:
  pool_size: 20
  max_overflow: 30
  pool_timeout: 30
  pool_recycle: 3600
  echo: false
```

## å»ºè®®/è§„åˆ’
- å»ºè®®æ ¹æ®å®é™…å¹¶å‘é‡è°ƒæ•´è¿æ¥æ± å’Œç¼“å­˜å‚æ•°ã€‚
- å»ºè®®å®šæœŸç›‘æ§ç³»ç»Ÿèµ„æºï¼ŒåŠæ—¶æ‰©å®¹ã€‚
- å¤æ‚çš„åŠ¨æ€workeræ± ã€å¤šçº§ç¼“å­˜ç­‰ä¸ºå»ºè®®/è§„åˆ’åŠŸèƒ½ï¼Œå½“å‰æœªå®ç°ã€‚

## æ€§èƒ½è°ƒä¼˜æ¦‚è¿°

### ä¼˜åŒ–ç›®æ ‡
- æé«˜APIå“åº”é€Ÿåº¦
- å¢åŠ å¹¶å‘å¤„ç†èƒ½åŠ›
- é™ä½èµ„æºæ¶ˆè€—
- æå‡ç³»ç»Ÿç¨³å®šæ€§

### ä¼˜åŒ–ç»´åº¦
- ç³»ç»Ÿé…ç½®ä¼˜åŒ–
- è¿æ¥æ± è°ƒä¼˜
- ç¼“å­˜ç­–ç•¥ä¼˜åŒ–
- æ•°æ®åº“ä¼˜åŒ–
- ç½‘ç»œä¼˜åŒ–

## ç³»ç»Ÿé…ç½®ä¼˜åŒ–

### 1. Workeré…ç½®
```yaml
# workeré…ç½®ä¼˜åŒ–
worker:
  pool_size: 20          # Workeræ± å¤§å°
  max_connections: 100   # æœ€å¤§è¿æ¥æ•°
  queue_size: 1000       # é˜Ÿåˆ—å¤§å°
  timeout: 30            # è¶…æ—¶æ—¶é—´
```

### 2. è¿æ¥æ± ç›‘æ§
```python
class ConnectionPoolMonitor:
    def __init__(self):
        self.metrics = {
            "total_connections": 0,
            "active_connections": 0,
            "idle_connections": 0,
            "connection_requests": 0,
            "connection_wait_time": 0
        }
    
    def get_utilization(self):
        """è·å–è¿æ¥æ± åˆ©ç”¨ç‡"""
        if self.metrics["total_connections"] == 0:
            return 0
        return (self.metrics["active_connections"] / 
                self.metrics["total_connections"]) * 100
    
    def should_expand(self):
        """åˆ¤æ–­æ˜¯å¦éœ€è¦æ‰©å®¹"""
        utilization = self.get_utilization()
        return utilization > 80 and self.metrics["connection_requests"] > 10
```

## è¿æ¥æ± è°ƒä¼˜

### è¿æ¥æ± å‚æ•°è¯´æ˜
```python
class ConnectionPoolConfig:
    def __init__(self):
        self.max_connections = 50      # æœ€å¤§è¿æ¥æ•°
        self.min_connections = 10      # æœ€å°è¿æ¥æ•°
        self.max_idle_time = 300       # ç©ºé—²è¶…æ—¶æ—¶é—´
        self.connection_timeout = 30   # è¿æ¥è¶…æ—¶æ—¶é—´
        self.keepalive_interval = 60   # ä¿æ´»é—´éš”
        self.keepalive_count = 3       # ä¿æ´»æ¬¡æ•°
```

### åŠ¨æ€è°ƒæ•´ç­–ç•¥
```python
class AdaptiveConnectionPool:
    def __init__(self, initial_size=10, max_size=100):
        self.current_size = initial_size
        self.max_size = max_size
        self.monitor = ConnectionPoolMonitor()
    
    def adjust_pool_size(self):
        """åŠ¨æ€è°ƒæ•´è¿æ¥æ± å¤§å°"""
        utilization = self.monitor.get_utilization()
        
        if utilization > 80 and self.current_size < self.max_size:
            # æ‰©å®¹
            new_size = min(self.current_size * 2, self.max_size)
            self.expand_pool(new_size)
        elif utilization < 30 and self.current_size > 10:
            # ç¼©å®¹
            new_size = max(self.current_size // 2, 10)
            self.shrink_pool(new_size)
```

## ç¼“å­˜ç­–ç•¥ä¼˜åŒ–

### å¤šçº§ç¼“å­˜æ¶æ„
```python
class MultiLevelCache:
    def __init__(self):
        self.l1_cache = {}  # å†…å­˜ç¼“å­˜
        self.l2_cache = Redis()  # Redisç¼“å­˜
        self.l3_cache = Database()  # æ•°æ®åº“ç¼“å­˜
    
    async def get(self, key):
        """å¤šçº§ç¼“å­˜æŸ¥è¯¢"""
        # L1ç¼“å­˜æŸ¥è¯¢
        if key in self.l1_cache:
            return self.l1_cache[key]
        
        # L2ç¼“å­˜æŸ¥è¯¢
        value = await self.l2_cache.get(key)
        if value:
            self.l1_cache[key] = value
            return value
        
        # L3ç¼“å­˜æŸ¥è¯¢
        value = await self.l3_cache.get(key)
        if value:
            await self.l2_cache.set(key, value)
            self.l1_cache[key] = value
            return value
        
        return None
```

### ç¼“å­˜é¢„çƒ­
```python
class CacheWarmer:
    def __init__(self, cache):
        self.cache = cache
    
    async def warm_up(self, keys):
        """ç¼“å­˜é¢„çƒ­"""
        for key in keys:
            value = await self.fetch_from_source(key)
            await self.cache.set(key, value)
    
    async def warm_up_devices(self, hostnames):
        """é¢„çƒ­è®¾å¤‡ä¿¡æ¯ç¼“å­˜"""
        for hostname in hostnames:
            # é¢„çƒ­è®¾å¤‡åŸºæœ¬ä¿¡æ¯
            device_info = await self.get_device_info(hostname)
            await self.cache.set(f"device:{hostname}", device_info)
            
            # é¢„çƒ­å¸¸ç”¨å‘½ä»¤ç»“æœ
            common_commands = ["show version", "show interfaces"]
            for command in common_commands:
                result = await self.execute_command(hostname, command)
                await self.cache.set(f"cmd:{hostname}:{command}", result)
```

## æ•°æ®åº“ä¼˜åŒ–

### æŸ¥è¯¢ä¼˜åŒ–
```python
class DatabaseOptimizer:
    def __init__(self, db):
        self.db = db
    
    async def optimize_queries(self):
        """æŸ¥è¯¢ä¼˜åŒ–"""
        # åˆ›å»ºç´¢å¼•
        await self.create_indexes()
        
        # åˆ†ææŸ¥è¯¢è®¡åˆ’
        await self.analyze_query_plans()
        
        # ä¼˜åŒ–æ…¢æŸ¥è¯¢
        await self.optimize_slow_queries()
    
    async def create_indexes(self):
        """åˆ›å»ºå¿…è¦çš„ç´¢å¼•"""
        indexes = [
            "CREATE INDEX IF NOT EXISTS idx_devices_hostname ON devices(hostname)",
            "CREATE INDEX IF NOT EXISTS idx_logs_timestamp ON logs(timestamp)",
            "CREATE INDEX IF NOT EXISTS idx_logs_hostname ON logs(hostname)"
        ]
        
        for index_sql in indexes:
            await self.db.execute(index_sql)
```

### æ•°æ®åˆ†åŒº
```python
class DataPartitioner:
    def __init__(self, db):
        self.db = db
    
    async def partition_logs_by_date(self):
        """æŒ‰æ—¥æœŸåˆ†åŒºæ—¥å¿—è¡¨"""
        partition_sql = """
        CREATE TABLE IF NOT EXISTS logs_2024_01 PARTITION OF logs
        FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');
        """
        await self.db.execute(partition_sql)
```

## ç½‘ç»œä¼˜åŒ–

### è¿æ¥å¤ç”¨
```python
class ConnectionReuser:
    def __init__(self):
        self.connections = {}
        self.lock = asyncio.Lock()
    
    async def get_connection(self, hostname):
        """è·å–æˆ–å¤ç”¨è¿æ¥"""
        async with self.lock:
            if hostname in self.connections:
                conn = self.connections[hostname]
                if conn.is_alive():
                    return conn
            
            # åˆ›å»ºæ–°è¿æ¥
            conn = await self.create_connection(hostname)
            self.connections[hostname] = conn
            return conn
    
    async def cleanup_idle_connections(self):
        """æ¸…ç†ç©ºé—²è¿æ¥"""
        current_time = time.time()
        async with self.lock:
            idle_hostnames = []
            for hostname, conn in self.connections.items():
                if current_time - conn.last_used > 300:  # 5åˆ†é’Ÿç©ºé—²
                    idle_hostnames.append(hostname)
            
            for hostname in idle_hostnames:
                conn = self.connections[hostname]
                await conn.close()
                del self.connections[hostname]
```

### è´Ÿè½½å‡è¡¡
```python
class LoadBalancer:
    def __init__(self, workers):
        self.workers = workers
        self.current_index = 0
    
    def get_next_worker(self):
        """è½®è¯¢é€‰æ‹©Worker"""
        worker = self.workers[self.current_index]
        self.current_index = (self.current_index + 1) % len(self.workers)
        return worker
    
    def get_least_loaded_worker(self):
        """é€‰æ‹©è´Ÿè½½æœ€è½»çš„Worker"""
        return min(self.workers, key=lambda w: w.get_load())
```

## æ€§èƒ½ç›‘æ§

### å…³é”®æŒ‡æ ‡
```python
class PerformanceMetrics:
    def __init__(self):
        self.metrics = {
            "api_response_time": [],
            "connection_pool_utilization": [],
            "cache_hit_rate": [],
            "database_query_time": [],
            "worker_queue_length": []
        }
    
    def record_api_response_time(self, response_time):
        """è®°å½•APIå“åº”æ—¶é—´"""
        self.metrics["api_response_time"].append(response_time)
        if len(self.metrics["api_response_time"]) > 1000:
            self.metrics["api_response_time"] = self.metrics["api_response_time"][-1000:]
    
    def get_average_response_time(self):
        """è·å–å¹³å‡å“åº”æ—¶é—´"""
        times = self.metrics["api_response_time"]
        return sum(times) / len(times) if times else 0
    
    def get_percentile_response_time(self, percentile=95):
        """è·å–ç™¾åˆ†ä½å“åº”æ—¶é—´"""
        times = sorted(self.metrics["api_response_time"])
        if not times:
            return 0
        
        index = int(len(times) * percentile / 100)
        return times[index]
```

### æ€§èƒ½å‘Šè­¦
```python
class PerformanceAlert:
    def __init__(self):
        self.thresholds = {
            "api_response_time": 2.0,      # 2ç§’
            "connection_pool_utilization": 90,  # 90%
            "cache_hit_rate": 80,          # 80%
            "database_query_time": 1.0     # 1ç§’
        }
    
    def check_alerts(self, metrics):
        """æ£€æŸ¥æ€§èƒ½å‘Šè­¦"""
        alerts = []
        
        if metrics.get("api_response_time", 0) > self.thresholds["api_response_time"]:
            alerts.append("APIå“åº”æ—¶é—´è¿‡é•¿")
        
        if metrics.get("connection_pool_utilization", 0) > self.thresholds["connection_pool_utilization"]:
            alerts.append("è¿æ¥æ± åˆ©ç”¨ç‡è¿‡é«˜")
        
        if metrics.get("cache_hit_rate", 100) < self.thresholds["cache_hit_rate"]:
            alerts.append("ç¼“å­˜å‘½ä¸­ç‡è¿‡ä½")
        
        return alerts
```

## æœ€ä½³å®è·µ

### 1. ç³»ç»Ÿè°ƒä¼˜
- æ ¹æ®ç¡¬ä»¶é…ç½®è°ƒæ•´Workeræ•°é‡
- åˆç†è®¾ç½®è¿æ¥æ± å¤§å°
- å¯ç”¨è¿æ¥å¤ç”¨
- é…ç½®é€‚å½“çš„è¶…æ—¶æ—¶é—´

### 2. ç¼“å­˜ä¼˜åŒ–
- ä½¿ç”¨å¤šçº§ç¼“å­˜æ¶æ„
- å®ç°ç¼“å­˜é¢„çƒ­
- è®¾ç½®åˆç†çš„TTL
- ç›‘æ§ç¼“å­˜å‘½ä¸­ç‡

### 3. æ•°æ®åº“ä¼˜åŒ–
- åˆ›å»ºå¿…è¦çš„ç´¢å¼•
- ä½¿ç”¨è¿æ¥æ± 
- å®ç°æ•°æ®åˆ†åŒº
- å®šæœŸæ¸…ç†å†å²æ•°æ®

### 4. ç½‘ç»œä¼˜åŒ–
- å¯ç”¨è¿æ¥å¤ç”¨
- å®ç°è´Ÿè½½å‡è¡¡
- ä¼˜åŒ–ç½‘ç»œé…ç½®
- ç›‘æ§ç½‘ç»œå»¶è¿Ÿ

## æ•…éšœæ’é™¤

### æ€§èƒ½é—®é¢˜è¯Šæ–­
```python
class PerformanceDiagnostic:
    def __init__(self):
        self.diagnostics = []
    
    def diagnose_slow_response(self):
        """è¯Šæ–­å“åº”æ…¢çš„é—®é¢˜"""
        checks = [
            self.check_connection_pool(),
            self.check_cache_performance(),
            self.check_database_performance(),
            self.check_network_latency()
        ]
        
        for check in checks:
            if check:
                self.diagnostics.append(check)
        
        return self.diagnostics
    
    def check_connection_pool(self):
        """æ£€æŸ¥è¿æ¥æ± çŠ¶æ€"""
        utilization = self.get_connection_pool_utilization()
        if utilization > 90:
            return f"è¿æ¥æ± åˆ©ç”¨ç‡è¿‡é«˜: {utilization}%"
        return None
```

### æ€§èƒ½è°ƒä¼˜æ£€æŸ¥æ¸…å•
- [ ] Workeræ•°é‡æ˜¯å¦åˆé€‚
- [ ] è¿æ¥æ± å¤§å°æ˜¯å¦åˆç†
- [ ] ç¼“å­˜é…ç½®æ˜¯å¦ä¼˜åŒ–
- [ ] æ•°æ®åº“æŸ¥è¯¢æ˜¯å¦é«˜æ•ˆ
- [ ] ç½‘ç»œè¿æ¥æ˜¯å¦å¤ç”¨
- [ ] ç›‘æ§æŒ‡æ ‡æ˜¯å¦æ­£å¸¸

## ğŸ“š ç›¸å…³æ–‡æ¡£

- **[é•¿è¿æ¥æŠ€æœ¯](../architecture/long-connection.md)** - æ ¸å¿ƒæŠ€æœ¯åŸç†
- **[æ‰¹é‡æ“ä½œ](batch-operations.md)** - å¤§è§„æ¨¡è®¾å¤‡ç®¡ç†

---

<div align="center">

**æ€§èƒ½è°ƒä¼˜ï¼Œè®© NetPulse è¿è¡Œæ›´é«˜æ•ˆï¼**

</div> 